# Домашнее задание к занятию "Установка Kubernetes"

### Цель задания

Установить кластер K8s.

### Чеклист готовности к домашнему заданию

1. Развернутые ВМ с ОС Ubuntu 20.04-lts


### Инструменты и дополнительные материалы, которые пригодятся для выполнения задания

1. [Инструкция по установке kubeadm](https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/)
2. [Документация kubespray](https://kubespray.io/)

-----

### Задание 1. Установить кластер k8s с 1 master node

1. Подготовка работы кластера из 3 нод: 1 мастер и 2 рабочие ноды.
![image](https://user-images.githubusercontent.com/99823951/235982707-9750fb19-d49a-4509-847e-e20dac486b70.png)  
Развернул 3 ВМ

2. В качестве CRI — containerd.  
3. Запуск etcd производить на мастере.  
4. Способ установки выбрать самостоятельно.  
Решил проводить установку через `kubeadm`  
Запускаю установку `kubelet kubeadm kubectl containerd` на всех нодах
```bash
ubuntu@nd1:~$ {
sudo apt-get update
sudo apt-get install -y apt-transport-https ca-certificates curl
sudo curl -fsSLo /etc/apt/keyrings/kubernetes-archive-keyring.gpg https://packages.cloud.google.com/apt/doc/apt-key.gpg
echo "deb [signed-by=/etc/apt/keyrings/kubernetes-archive-keyring.gpg] https://apt.kubernetes.io/ kubernetes-xenial main" | sudo tee /etc/apt/sources.list.d/kubernetes.list
sudo apt-get update
sudo apt-get install -y kubelet kubeadm kubectl containerd
sudo apt-mark hold kubelet kubeadm kubectl
}
```
Произвожу инициализацию кластера. Указываю ip master-ноды, ip сети для pod-ов и ip-внешний (для генерация сертификата, чтобы подключаться из вне)  
```bash
ubuntu@nd1:~$ kubeadm init \
  --apiserver-advertise-address=10.129.0.8 \
  --pod-network-cidr 10.224.0.0/16 \
  --apiserver-cert-extra-sans=158.160.30.169 
```
Включаю `forwarding`, без него `kubeadm Init` не проходит
```bash
ubuntu@nd1:~$ sudo -i
root@nd1:~# modprobe br_netfilter
echo "net.ipv4.ip_forward=1" >> /etc/sysctl.conf
echo "net.bridge.bridge-nf-call-iptables=1" >> /etc/sysctl.conf
echo "net.bridge.bridge-nf-call-arptables=1" >> /etc/sysctl.conf
echo "net.bridge.bridge-nf-call-ip6tables=1" >> /etc/sysctl.conf
sysctl -p /etc/sysctl.conf
```
Получаю токен для подключения воркеров к кластеру  
```bash
ubuntu@nd2:~$ sudo kubeadm join 10.129.0.8:6443 --token d77lac.98314r3c7ucdulpe         --discovery-token-ca-cert-hash sha256:a1a5e534e879ea80ec86c4b46d04506d4c3b090e5296bee9475571eba0ae76f1 
```
```bash
ubuntu@nd3:~$ sudo kubeadm join 10.129.0.8:6443 --token d77lac.98314r3c7ucdulpe         --discovery-token-ca-cert-hash sha256:a1a5e534e879ea80ec86c4b46d04506d4c3b090e5296bee9475571eba0ae76f1 

...........................

This node has joined the cluster:
* Certificate signing request was sent to apiserver and a response was received.
* The Kubelet was informed of the new secure connection details.

```
Копирую админ конфиг в профиль текущего пользователя, для возможности запуска `kubectl`  
```bash
ubuntu@nd1:~$ {
mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
}
ubuntu@nd1:~$ kubectl get nodes
NAME   STATUS     ROLES           AGE     VERSION
nd1    NotReady   control-plane   7m29s   v1.27.1
nd2    NotReady   <none>          4m54s   v1.27.1
nd3    NotReady   <none>          4m10s   v1.27.1
```
Поиск проблемы через `describe nodes` выдал сообщение, что `not ready: NetworkReady=false reason:NetworkPluginNotReady message:Network plugin returns error: cni plugin not initialized`. Поэтому идем устанавливать плагин сети  
```bash
ubuntu@nd1:~$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
```

5. Настроить подключение с локальной машины.
Переключаюсь на локальную машину, копирую конфиг себе в `~/.kube/config` и проверяем работу.
```bash
ubuntu@ubuntu-VirtualBox:~/.kube$ kubectl get nodes
NAME   STATUS   ROLES           AGE   VERSION
nd1    Ready    control-plane   28m   v1.27.1
nd2    Ready    <none>          26m   v1.27.1
nd3    Ready    <none>          25m   v1.27.1

ubuntu@ubuntu-VirtualBox:~/.kube$ kubectl get pod -A
NAMESPACE      NAME                          READY   STATUS              RESTARTS        AGE
kube-flannel   kube-flannel-ds-fxkfs         0/1     CrashLoopBackOff    7 (3m31s ago)   14m
kube-flannel   kube-flannel-ds-k8dn4         0/1     CrashLoopBackOff    7 (3m43s ago)   14m
kube-flannel   kube-flannel-ds-nkt6c         0/1     CrashLoopBackOff    7 (3m26s ago)   14m
kube-system    coredns-5d78c9869d-kq4cz      0/1     ContainerCreating   0               28m
kube-system    coredns-5d78c9869d-xk5qw      0/1     ContainerCreating   0               28m
kube-system    etcd-nd1                      1/1     Running             5 (7m53s ago)   27m
kube-system    kube-apiserver-nd1            1/1     Running             6 (7m11s ago)   28m
kube-system    kube-controller-manager-nd1   1/1     Running             8 (7m42s ago)   29m
kube-system    kube-proxy-2sl52              0/1     CrashLoopBackOff    8 (53s ago)     26m
kube-system    kube-proxy-6g7rg              0/1     CrashLoopBackOff    8 (82s ago)     28m
kube-system    kube-proxy-xjfgv              1/1     Running             8 (6m23s ago)   26m
kube-system    kube-scheduler-nd1            1/1     Running             8 (7m38s ago)   27m
```

